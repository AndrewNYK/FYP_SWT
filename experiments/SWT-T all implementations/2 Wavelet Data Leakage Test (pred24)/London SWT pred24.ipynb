{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c52fc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import time\n",
    "sys.path.append(\"./Models\")\n",
    "import os\n",
    "os.system('')\n",
    "\n",
    "import subprocess\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import pickle\n",
    "import pgzip\n",
    "import copy\n",
    "\n",
    "import datetime\n",
    "\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c2d59d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default settings for experiment\n",
    "arg_model = \"tsrnn\" #Options: 'trfbb', 'tsrnn', 'trfbf'\n",
    "arg_dset = \"lsm\" #Datasets -- Spain: 'ree', AEP, DAYTON: 'dyt' London: 'lsm'\n",
    "\n",
    "attr_dset_smpl_rt = 24 if arg_dset == \"AEP\" else (48 if arg_dset == \"lsm\" else 24) #Samples per day. Spain, AEP: 24, London: 48\n",
    "param_dset_lookback_weeks = 5\n",
    "param_dset_forecast = 48 \n",
    "# param_dset_lookback_weeks = 9\n",
    "# param_dset_forecast = 168 # 3.5days = 168\n",
    "param_dset_train_stride = 48 #Choose a coprime value to the forecast so all reading frames are eventually considered\n",
    "param_dset_test_stride = 'same' #tsrnn paper uses 1 week\n",
    "param_dset_lookback = param_dset_lookback_weeks*7*attr_dset_smpl_rt - param_dset_forecast\n",
    "\n",
    "param_trf_weather = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f5c66ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path='Datasets/LondonSmartMeter' # if under experiments folder\n",
    "path = '.'\n",
    "seq_len = param_dset_lookback\n",
    "pred_horz = param_dset_forecast\n",
    "weather = param_trf_weather\n",
    "timestamps = False\n",
    "weather = False\n",
    "\n",
    "\n",
    "if 'lsm_dict.pkl.pgz' not in os.listdir(path):\n",
    "    subprocess.check_call('python ./LondonSmartMeter_hhour.py ./LondonSmartMeter lsm_dict.pkl')\n",
    "if 'londonWeather.pkl.pgz' not in os.listdir(path):   \n",
    "    raise ValueError\n",
    "\n",
    "with pgzip.open(os.path.join(path,'lsm_dict.pkl.pgz'),'rb') as f:\n",
    "    s_dict = pickle.load(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93d356f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "5561\n",
      "torch.Size([24192])\n"
     ]
    }
   ],
   "source": [
    "# print(s_dict)\n",
    "print(len(s_dict[2]))\n",
    "print(len(s_dict))\n",
    "\n",
    "print(s_dict[2][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcf0cd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Get the maximum decomposition level\n",
    "def print_maximal_decom_level(data):\n",
    "    max_level = pywt.swt_max_level(data)\n",
    "    print(\"Maximum decomposition level:\", max_level)\n",
    "    \n",
    "    return max_level\n",
    "\n",
    "# SWT functions\n",
    "def data_preparation(dataset, window, lev):\n",
    "    da = []\n",
    "    max_level = print_maximal_decom_level(window)\n",
    "    for i in tqdm(range(len(dataset)), total=len(dataset), desc=\"swt\"):\n",
    "        coeffs = pywt.swt(dataset[i], wavelet='db2', level=lev)\n",
    "        da.append(coeffs);\n",
    "    return da\n",
    "\n",
    "def data_reconstruction(dataset):\n",
    "    da = []\n",
    "    for i in tqdm(range(len(dataset)), total= len(dataset), desc=\"iswt\"):\n",
    "#         recon = pywt.iswt(dataset[i,:,:,:].tolist(), 'db2')\n",
    "        recon = pywt.iswt(dataset[i], 'db2')\n",
    "#         print(np.array(recon).shape)\n",
    "        da.append(recon)\n",
    "#         da.append(recon[0][window-1])\n",
    "    return da\n",
    "\n",
    "\n",
    "# Called because iswt cannot accept tolist() dataset\n",
    "def data_organization(coeffs):\n",
    "    '''\n",
    "    Reshape data back to (n,3,2,window_length), where there are 3 tuples of 2 values consisting of \n",
    "    coeffs array_like Coefficients list of tuples:\n",
    "    [(cAn, cDn), ..., (cA2, cD2), (cA1, cD1)]\n",
    "    '''\n",
    "    reshape_list = []\n",
    "    for i in range(len(coeffs)):\n",
    "        reshape_list.append([])\n",
    "        for j in range(len(coeffs[0])):\n",
    "            reshape_list[i].append(tuple(coeffs[i][j]))\n",
    "            \n",
    "    return reshape_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e0d3dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before series: torch.Size([14, 1680])\n",
      "start_times_ after:  [[2012, 10, 12, 0, 30, 0], [2012, 11, 16, 0, 30, 0], [2012, 12, 21, 0, 30, 0], [2013, 1, 25, 0, 30, 0], [2013, 3, 1, 0, 30, 0], [2013, 4, 5, 0, 30, 0], [2013, 5, 10, 0, 30, 0], [2013, 6, 14, 0, 30, 0], [2013, 7, 19, 0, 30, 0], [2013, 8, 23, 0, 30, 0], [2013, 9, 27, 0, 30, 0], [2013, 11, 1, 0, 30, 0], [2013, 12, 6, 0, 30, 0], [2014, 1, 10, 0, 30, 0]]\n",
      "start_times after:  [[2012, 10, 12, 0, 30, 0], [2012, 11, 16, 0, 30, 0], [2012, 12, 21, 0, 30, 0], [2013, 1, 25, 0, 30, 0], [2013, 3, 1, 0, 30, 0], [2013, 4, 5, 0, 30, 0], [2013, 5, 10, 0, 30, 0], [2013, 6, 14, 0, 30, 0], [2013, 7, 19, 0, 30, 0], [2013, 8, 23, 0, 30, 0], [2013, 9, 27, 0, 30, 0], [2013, 11, 1, 0, 30, 0], [2013, 12, 6, 0, 30, 0], [2014, 1, 10, 0, 30, 0]]\n",
      "before concat series: 5561\n",
      "before concat series: torch.Size([14, 1680])\n",
      "before normalization series: torch.Size([97143, 1680, 1])\n",
      "total series shape:  torch.Size([97143, 1680, 1])\n"
     ]
    }
   ],
   "source": [
    "self_has_weather = weather\n",
    "self_return_timestamps = timestamps\n",
    "\n",
    "self_weather_dict = None\n",
    "if self_has_weather:\n",
    "    with pgzip.open(os.path.join(path,'londonWeather.pkl.pgz'),'rb') as f2:\n",
    "        weather_dict = pickle.load(f2)\n",
    "\n",
    "    self_weather_dict = weather_dict\n",
    "\n",
    "#s_dict is dictionary as follows: { lclid: (start_timestamp,Tensor), ...}\n",
    "\n",
    "#List to store the dataset indices corresponding to each household\n",
    "self_household_idxs = [None]*len(s_dict)\n",
    "#List to hold the split series\n",
    "self_series = [None]*len(s_dict)\n",
    "#These two lists will be converted to torch tensors\n",
    "self_start_times = []\n",
    "self_pred_starttimes = []\n",
    "#These two lists stores the datetime format\n",
    "self_start_times__ = []\n",
    "#self.pred_starttimes__ = []\n",
    "\n",
    "index_count = 0\n",
    "\n",
    "# Enumerate all keys in dictionary -> lclid\n",
    "for index, lclid in enumerate(s_dict.keys()):    \n",
    "    start_time, s_tensor = s_dict[lclid]\n",
    "    #start_time[0] = start_time[0]%400\n",
    "    \n",
    "    #pad_amt = (seq_len+pred_horz) - (len(s_tensor)%(seq_len+pred_horz))\n",
    "    #s_tensor = torch.nn.functional.pad(s_tensor,pad = (pad_amt,0), value = torch.nan)\n",
    "    \n",
    "    #Split into chunks of seq_len+pred_horz length each\n",
    "    s_tensors = s_tensor.split(seq_len+pred_horz)\n",
    "\n",
    "    #Compute start timestamps for splits\n",
    "    start_times = [None]*len(s_tensors)\n",
    "    pred_starttimes = [None]*len(s_tensors)\n",
    "\n",
    "    for i in range(len(start_times)):\n",
    "        minutes_delta = 30*i*(seq_len + pred_horz)\n",
    "        time_delta = datetime.timedelta(minutes=minutes_delta)\n",
    "        new_start_time = start_time + time_delta\n",
    "        start_times[i] = new_start_time\n",
    "\n",
    "    # Reinitialised for computation of prediction start time\n",
    "    minutes_delta = 30*seq_len\n",
    "    time_delta = datetime.timedelta(minutes=minutes_delta)\n",
    "\n",
    "    #Compute prediction start timestamps\n",
    "    for i in range(len(pred_starttimes)):\n",
    "        new_predtime = start_times[i] + time_delta\n",
    "        pred_starttimes[i] = [new_predtime.year,\n",
    "                              new_predtime.month,\n",
    "                              new_predtime.day,\n",
    "                              new_predtime.hour,\n",
    "                              new_predtime.minute,\n",
    "                              new_predtime.second]\n",
    "\n",
    "    ''' \n",
    "    A shallow copy, li2, is created using copy.copy(), \n",
    "    preserving the top-level structure but sharing references to the inner lists. \n",
    "    A deep copy, li3, is created using copy.deepcopy(), resulting in a completely \n",
    "    independent copy of li1, including all nested elements\n",
    "    '''\n",
    "    \n",
    "    start_times__ = copy.deepcopy(start_times)\n",
    "    for i in range(len(start_times)):\n",
    "        new_start_time = start_times[i]\n",
    "        start_times[i] = [new_start_time.year,\n",
    "                          new_start_time.month,\n",
    "                          new_start_time.day,\n",
    "                          new_start_time.hour,\n",
    "                          new_start_time.minute,\n",
    "                          new_start_time.second]\n",
    "\n",
    "    #Remove last if length less than the others\n",
    "    if s_tensors[-1].shape[0] < seq_len+pred_horz:\n",
    "        s_tensors = s_tensors[:-1]\n",
    "        start_times = start_times[:-1]\n",
    "        pred_starttimes = pred_starttimes[:-1]\n",
    "        start_times__ = start_times__[:-1]\n",
    "\n",
    "    if len(s_tensors) == 0:\n",
    "        self_series[index] = torch.empty(0)                    \n",
    "    else:\n",
    "        '''\n",
    "        torch.stack()\n",
    "        Concatenates a sequence of tensors along a new dimension.\n",
    "        All tensors need to be of the same size.\n",
    "        '''\n",
    "        s_tensors = torch.stack(s_tensors)\n",
    "        # Remove invalid (more than 4/5 (80%) of series is 0 or nan)\n",
    "        s_tensors[s_tensors==0] = torch.nan # 0s are invalid too, replace with nan\n",
    "        # Count those tensor index with less than 80% invalid\n",
    "        sel = (( (s_tensors==0) | s_tensors.isnan()).sum(dim=-1) < (4*(seq_len+pred_horz)//5))\n",
    "        s_tensors = s_tensors[sel]\n",
    "        \n",
    "        # Get start, prediction times for those with less than 80% nan\n",
    "        start_times_ = [start_times[i] for i in range(len(start_times)) if sel[i]]\n",
    "        pred_starttimes_ = [pred_starttimes[i] for i in range(len(pred_starttimes)) if sel[i]]\n",
    "        _start_times__ = [ start_times__[i] for i in range(len(start_times__)) if sel[i]]\n",
    "        \n",
    "        self_series[index] = s_tensors\n",
    "        if index==0:\n",
    "            print(\"before series:\", self_series[0].shape)\n",
    "        self_start_times = self_start_times + start_times_\n",
    "        if index==0:\n",
    "            print(\"start_times_ after: \", start_times_)\n",
    "            print(\"start_times after: \", start_times)\n",
    "        self_pred_starttimes = self_pred_starttimes + pred_starttimes_\n",
    "        self_start_times__ = self_start_times__ + _start_times__\n",
    "\n",
    "    if len(s_tensors) == 0:\n",
    "        self_household_idxs[index] = []\n",
    "    else:\n",
    "        self_household_idxs[index] = list(range(index_count,index_count+len(s_tensors)))\n",
    "        index_count = index_count + len(s_tensors)\n",
    "        \n",
    "print(\"before concat series:\", len(self_series))\n",
    "print(\"before concat series:\", self_series[0].shape)\n",
    "# Concat all households series but retain 1680 seq_len predictions\n",
    "self_series = torch.cat(self_series,dim=0).unsqueeze(-1)\n",
    "print(\"before normalization series:\", self_series.shape)\n",
    "\n",
    "self_start_times = torch.tensor(self_start_times,dtype = torch.long)\n",
    "self_pred_starttimes = torch.tensor(self_pred_starttimes,dtype = torch.long)\n",
    "\n",
    "#self.series[:,:seq_len] = self.series[:,:seq_len].nan_to_num(nan=0.,posinf=0.,neginf=0.)\n",
    "\n",
    "#Series normalization\n",
    "smin = self_series.nan_to_num(nan=torch.finfo(self_series.dtype).max).amin(dim=-2,keepdim=True)\n",
    "smax = self_series.nan_to_num(nan=torch.finfo(self_series.dtype).min).amax(dim=-2,keepdim=True)\n",
    "# Normalize over dimension -2, which is seq_len + prediction len\n",
    "self_series = (self_series - smin.broadcast_to(self_series.shape))/(smax-smin+1e-10).broadcast_to(self_series.shape)\n",
    "\n",
    "print(\"total series shape: \", self_series.shape)\n",
    "\n",
    "#SWT Transformation\n",
    "## INPUT HERE\n",
    "\n",
    "if self_has_weather:\n",
    "    #Weather series normalization\n",
    "    #Only dimensions 0, 3, 4, 5, 6, 7 needs normalization\n",
    "    wdmin = self_weather_dict['tensor'].nan_to_num(nan=torch.finfo(self_weather_dict['tensor'].dtype).max).amin(dim=-2,keepdim=True)\n",
    "    wdmax = self_weather_dict['tensor'].nan_to_num(nan=torch.finfo(self_weather_dict['tensor'].dtype).min).amax(dim=-2,keepdim=True)\n",
    "    self_weather_dict['tensor'] = (self_weather_dict['tensor'] - wdmin.broadcast_to(self_weather_dict['tensor'].shape))\\\n",
    "        /(wdmax-wdmin + 1e-10).broadcast_to(self_weather_dict['tensor'].shape)\n",
    "\n",
    "    self_weather_dict['tensor'] = self_weather_dict['tensor'].type(torch.float32)\n",
    "\n",
    "self_length = len(self_series)\n",
    "self_seq_len = seq_len\n",
    "self_pred_horz = pred_horz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a03b3057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total series shape after squeeze:  torch.Size([97143, 1680])\n",
      "torch shape:  torch.Size([97143, 1680])\n",
      "numpy shape:  (97143, 1680)\n",
      "tensor([   nan,    nan,    nan,  ..., 0.0807, 0.1022, 0.0879])\n",
      "[       nan        nan        nan ... 0.08074533 0.10224557 0.08791208]\n",
      "Maximum decomposition level: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2987da5d404faca0f2016cc0fb2194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "swt:   0%|          | 0/97143 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([nan, nan, nan, ..., nan, nan, nan], dtype=float32), array([nan, nan, nan, ..., nan, nan, nan], dtype=float32))\n",
      "(97143, 3, 2, 1680)\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "(97143, 10080)\n",
      "(97143, 6, 1680)\n"
     ]
    }
   ],
   "source": [
    "#SWT Transformation\n",
    "self_series = self_series.squeeze(-1)\n",
    "print(\"total series shape after squeeze: \", self_series.shape)\n",
    "self_series_numpy = self_series.numpy()\n",
    "print(\"torch shape: \", self_series.shape)\n",
    "print(\"numpy shape: \", self_series_numpy.shape)\n",
    "print(self_series[0])\n",
    "print(self_series_numpy[0])\n",
    "lev = 3\n",
    "da = data_preparation(self_series_numpy, self_series_numpy.shape[1], lev)\n",
    "print(da[0][0])\n",
    "\n",
    "Vv = np.array(da)\n",
    "print(Vv.shape)\n",
    "print(Vv[0][0])\n",
    "\n",
    "vv = Vv.reshape(Vv.shape[0],2*lev*Vv.shape[3])\n",
    "print(vv.shape)\n",
    "\n",
    "\n",
    "# dataset = scaler.fit_transform(vv)\n",
    "\n",
    "dat = vv.reshape(Vv.shape[0],2*lev,Vv.shape[3])\n",
    "print(dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d566a8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 6, 1680)\n",
      "(120, 6, 1632)\n",
      "(40, 6, 1632)\n",
      "(40, 6, 1632)\n",
      "(120, 6, 48)\n",
      "(120, 1632, 6)\n",
      "(40, 1632, 6)\n",
      "(40, 1632, 6)\n"
     ]
    }
   ],
   "source": [
    "dat = dat[1000:1200]\n",
    "\n",
    "print(dat.shape)\n",
    "# alpha=0.6667\n",
    "\n",
    "alpha = 0.6\n",
    "beta = 0.8\n",
    "\n",
    "\n",
    "trainX,trainY=dat[:int(dat.shape[0]*alpha),:,:param_dset_lookback],dat[:int(dat.shape[0]*alpha),:,param_dset_lookback:]\n",
    "valX,valY=dat[int(dat.shape[0]*alpha):int(dat.shape[0]*beta),:,:param_dset_lookback],dat[int(dat.shape[0]*alpha):int(dat.shape[0]*beta),:,param_dset_lookback:]\n",
    "testX,testY=dat[int(dat.shape[0]*beta):,:,:param_dset_lookback],dat[int(dat.shape[0]*beta):,:,param_dset_lookback:]\n",
    "\n",
    "# trainY = trainY.reshape([trainY.shape[0], trainY.shape[1]*trainY.shape[2]])\n",
    "# valY = valY.reshape([valY.shape[0], valY.shape[1]*valY.shape[2]])\n",
    "# testY = testY.reshape([testY.shape[0], testY.shape[1]*testY.shape[2]])\n",
    "\n",
    "print(trainX.shape)\n",
    "print(valX.shape)\n",
    "print(testX.shape)\n",
    "print(trainY.shape)\n",
    "\n",
    "trainX=np.transpose(trainX, (0, 2, 1))\n",
    "valX =np.transpose(valX, (0, 2, 1))\n",
    "testX=np.transpose(testX, (0, 2, 1))\n",
    "\n",
    "print(trainX.shape)\n",
    "print(valX.shape)\n",
    "print(testX.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979e36f9",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9abf1110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b50fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time2Vector(nn.Module):\n",
    "    def __init__(self, seq_len):\n",
    "        super(Time2Vector, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        self.weights_linear = nn.Parameter(torch.rand(seq_len, requires_grad=True))\n",
    "        self.bias_linear = nn.Parameter(torch.rand(seq_len), requires_grad=True)\n",
    "        self.weights_periodic = nn.Parameter(torch.rand(seq_len), requires_grad=True)\n",
    "        self.bias_periodic = nn.Parameter(torch.rand(seq_len), requires_grad=True)\n",
    "        \n",
    "        # Initialize parameters with uniform distribution\n",
    "        nn.init.uniform_(self.weights_linear, a=0.0, b=1.0)\n",
    "        nn.init.uniform_(self.bias_linear, a=0.0, b=1.0)\n",
    "        nn.init.uniform_(self.weights_periodic, a=0.0, b=1.0)\n",
    "        nn.init.uniform_(self.bias_periodic, a=0.0, b=1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.mean(x[:, :, :], dim=-1)\n",
    "        time_linear = self.weights_linear * x + self.bias_linear\n",
    "        time_linear = time_linear.unsqueeze(-1)\n",
    "\n",
    "        time_periodic = torch.sin(x * self.weights_periodic + self.bias_periodic)\n",
    "        time_periodic = time_periodic.unsqueeze(-1)\n",
    "\n",
    "        return torch.cat([time_linear, time_periodic], dim=-1)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f'seq_len={self.seq_len}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "973b717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAttention(nn.Module):\n",
    "    def __init__(self, d_k, d_v):\n",
    "        super(SingleAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "        self.query = nn.Linear(in_features=8, out_features=d_k)\n",
    "        nn.init.xavier_uniform_(self.query.weight)\n",
    "        nn.init.zeros_(self.query.bias)\n",
    "\n",
    "        self.key = nn.Linear(in_features=8, out_features=d_k)\n",
    "        nn.init.xavier_uniform_(self.key.weight)\n",
    "        nn.init.zeros_(self.key.bias)\n",
    "\n",
    "        self.value = nn.Linear(in_features=8, out_features=d_v)\n",
    "        nn.init.xavier_uniform_(self.value.weight)\n",
    "        nn.init.zeros_(self.value.bias)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        q = self.query(inputs[0])\n",
    "        k = self.key(inputs[1])\n",
    "\n",
    "        attn_weights = torch.matmul(q, k.transpose(-2, -1))\n",
    "        attn_weights = attn_weights / torch.sqrt(torch.tensor(self.d_k, dtype=torch.float32))\n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "\n",
    "        v = self.value(inputs[2])\n",
    "        attn_out = torch.matmul(attn_weights, v)\n",
    "        return attn_out\n",
    "    \n",
    "class MultiAttention(nn.Module):\n",
    "    def __init__(self, d_k, d_v, n_heads):\n",
    "        super(MultiAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        self.attn_heads = nn.ModuleList([SingleAttention(d_k, d_v) for _ in range(n_heads)])\n",
    "        \n",
    "        self.linear = nn.Linear(d_k * n_heads, 8)\n",
    "        nn.init.xavier_uniform_(self.linear.weight)\n",
    "        nn.init.zeros_(self.linear.bias)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]\n",
    "        concat_attn = torch.cat(attn, dim=-1)\n",
    "        multi_linear = self.linear(concat_attn)\n",
    "        return multi_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c516d8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_k, d_v, n_heads, ff_dim, seq_len, dropout=0.1):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.n_heads = n_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.dropout_rate = dropout\n",
    "\n",
    "        self.attn_multi = MultiAttention(d_k, d_v, n_heads)\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        self.attn_normalize = nn.LayerNorm(normalized_shape=8, eps=1e-6)\n",
    "\n",
    "#         self.ff_conv1D_1 = nn.Conv1d(in_channels=8, out_channels=self.ff_dim, kernel_size=1)\n",
    "        self.ff_conv1D_1 = nn.Conv1d(in_channels=seq_len, out_channels=self.ff_dim, kernel_size=1)\n",
    "#         self.ff_conv1D_2 = nn.Conv1d(in_channels=self.ff_dim, out_channels=8, kernel_size=1)\n",
    "        self.ff_conv1D_2 = nn.Conv1d(in_channels=self.ff_dim, out_channels=seq_len, kernel_size=1)\n",
    "        self.ff_dropout = nn.Dropout(dropout)\n",
    "        self.ff_normalize = nn.LayerNorm(normalized_shape=8, eps=1e-6)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "#         print(len(inputs))\n",
    "#         print(inputs[0].shape)\n",
    "        attn_layer = self.attn_multi(inputs)\n",
    "        attn_layer = self.attn_dropout(attn_layer)\n",
    "        attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n",
    "\n",
    "        # Correction for transpose\n",
    "#         ff_layer = self.ff_conv1D_1(attn_layer.transpose(1, 2))\n",
    "        ff_layer = self.ff_conv1D_1(attn_layer)\n",
    "        ff_layer = F.relu(ff_layer)\n",
    "#         ff_layer = self.ff_conv1D_2(ff_layer).transpose(1, 2)\n",
    "        ff_layer = self.ff_conv1D_2(ff_layer)\n",
    "        ff_layer = self.ff_dropout(ff_layer)\n",
    "        ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
    "        return ff_layer\n",
    "    \n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, d_k, d_v, n_heads, ff_dim, seq_len, dropout=0.1):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.n_heads = n_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.dropout_rate = dropout\n",
    "\n",
    "        self.attn_multi = MultiAttention(d_k, d_v, n_heads)\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        self.attn_normalize = nn.LayerNorm(normalized_shape=8, eps=1e-6)\n",
    "\n",
    "#         self.ff_conv1D_1 = nn.Conv1d(in_channels=8, out_channels=8, kernel_size=1)\n",
    "        self.ff_conv1D_1 = nn.Conv1d(in_channels=seq_len, out_channels=seq_len, kernel_size=1)\n",
    "        self.ff_dropout = nn.Dropout(dropout)\n",
    "        self.ff_normalize = nn.LayerNorm(normalized_shape=8, eps=1e-6)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        attn_layer = self.attn_multi(inputs)\n",
    "        attn_layer = self.attn_dropout(attn_layer)\n",
    "        attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n",
    "        \n",
    "        # Transpose for pytorch implementation\n",
    "#         ff_layer = self.ff_conv1D_1(attn_layer.transpose(1, 2)).transpose(1, 2)\n",
    "        ff_layer = self.ff_conv1D_1(attn_layer)\n",
    "        ff_layer = F.relu(ff_layer)\n",
    "        ff_layer = self.ff_dropout(ff_layer)\n",
    "        ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
    "        return ff_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "080fde85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SWT_Transformer(nn.Module):\n",
    "    def __init__(self, seq_len, inp_len, out_len, d_k, d_v, n_heads, ff_dim, param_dset_forecast):\n",
    "        super(SWT_Transformer, self).__init__()\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.time_embedding = Time2Vector(seq_len)\n",
    "        \n",
    "        self.layer1 = TransformerEncoder(d_k, d_v, n_heads, ff_dim, seq_len)\n",
    "        self.layer2 = TransformerEncoder(d_k, d_v, n_heads, ff_dim, seq_len)\n",
    "        self.layer3 = TransformerEncoder(d_k, d_v, n_heads, ff_dim, seq_len)\n",
    "        self.layer4 = TransformerDecoder(d_k, d_v, n_heads, ff_dim, seq_len)\n",
    "        self.layer5 = TransformerDecoder(d_k, d_v, n_heads, ff_dim, seq_len)\n",
    "\n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)\n",
    "#         self.fc1 = nn.Linear(seq_len, 128)\n",
    "#         self.fc2 = nn.Linear(128, 48)\n",
    "        self.fc1 = nn.Linear(seq_len, 512)\n",
    "        self.fc2 = nn.Linear(512, 6*param_dset_forecast)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_seq = x\n",
    "        \n",
    "        time_embedding = self.time_embedding(in_seq)\n",
    "        x = torch.cat([in_seq, time_embedding], dim=-1)\n",
    "        \n",
    "        x = self.layer1((x, x, x))\n",
    "        x = self.layer2((x, x, x))\n",
    "        x = self.layer3((x, x, x))\n",
    "        x = self.layer4((x, x, x))\n",
    "        x = self.layer5((x, x, x))\n",
    "#         print(\"1\", x.shape)\n",
    "\n",
    "        x = self.pooling(x).squeeze(2)\n",
    "#         print(\"2\", x.shape)\n",
    "        x = F.dropout(x, p=0.1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "#         print(\"3\", x.shape)\n",
    "        x = F.dropout(x, p=0.1)\n",
    "        out = self.fc2(x)\n",
    "#         print(\"4\", out.shape)\n",
    "        out = out.reshape((out.shape[0],6,out.shape[1]//6))\n",
    "#         print(\"5\", out.shape)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f52ef6",
   "metadata": {},
   "source": [
    "## Create model and data tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c11a8ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "d_k = 256\n",
    "d_v = 256\n",
    "n_heads = 12\n",
    "ff_dim = 256\n",
    "lev=3\n",
    "inp_len=2*lev\n",
    "out_len=2*lev\n",
    "seq_len = param_dset_lookback\n",
    "\n",
    "# seq_len = 1\n",
    "# window = 200\n",
    "# look_back = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e83f32b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual number of model parameters: 9370696\n",
      "Trainable model parameters: 9370696\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29addabe93644a7afacd8a4f4a7ee44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epochs:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fea84814b9e47ba941e16d493589316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dccd55e46183488f9f9db4bb158f64dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4, Training Loss: 0.146346, Validation Loss: 0.049197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303945f6c28745119e8b255ff029a50b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910c359f389b402e8784da531d9f8705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4, Training Loss: 0.054351, Validation Loss: 0.040148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cdb7360710148d499b7f4d4d9f40b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3181dfde3c64d45a2944eb20af56eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4, Training Loss: 0.050088, Validation Loss: 0.038004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c296b980364b6dbf5e69c7dad3cb96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2085c6bd84234bfeaf530b43a7cd3c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4, Training Loss: 0.048867, Validation Loss: 0.036981\n"
     ]
    }
   ],
   "source": [
    "# model = create_model()\n",
    "# model.summary()\n",
    "\n",
    "# # Training data\n",
    "# X_train, y_train = trainX,trainY\n",
    "# ###############################################################################\n",
    "# # Validation data\n",
    "# X_val, y_val = testX,testY\n",
    "# ###############################################################################\n",
    "# # Test data\n",
    "# X_test, y_test = testX_a,testY_a\n",
    "# callback = tf.keras.callbacks.ModelCheckpoint('Transformer_5min.hdf5',\n",
    "#                                                       monitor='val_loss',\n",
    "#                                                       save_best_only=True,\n",
    "#                                                       verbose=1)\n",
    "# with tf.device(\"/gpu:0\"):\n",
    "#     history = model.fit(X_train, y_train,\n",
    "#                             batch_size=batch_size,\n",
    "# #                             epochs=50,\n",
    "#                             epochs=1,\n",
    "#                             validation_data=(X_val, y_val),\n",
    "#                             callbacks=[callback])\n",
    "\n",
    "# model = tf.keras.models.load_model('Transformer_5min.hdf5',\n",
    "#                                            custom_objects={'Time2Vector': Time2Vector,\n",
    "#                                                            'SingleAttention': SingleAttention,\n",
    "#                                                            'MultiAttention': MultiAttention,\n",
    "#                                                            'TransformerEncoder': TransformerEncoder,\n",
    "#                                                            'TransformerDecoder': TransformerDecoder}\n",
    "#                                            )\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create PyTorch model\n",
    "model = SWT_Transformer(seq_len, inp_len, out_len, d_k, d_v, n_heads, ff_dim, param_dset_forecast)\n",
    "\n",
    "# Print model summary\n",
    "# print(model)\n",
    "def num_parameters(m):\n",
    "    return sum([p.numel() for p in m.parameters()])\n",
    "\n",
    "parameters = num_parameters(model)\n",
    "\n",
    "# print(f\"Expected number of parameters: {m * dk * dk + m * 1 * 1 * n}\")\n",
    "print(f\"Actual number of model parameters: {parameters}\")\n",
    "\n",
    "trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad\n",
    ")\n",
    "print(f\"Trainable model parameters: {trainable_params}\" )\n",
    "\n",
    "# total_params = 0\n",
    "# for name, parameter in model.named_parameters():\n",
    "#     if not parameter.requires_grad:\n",
    "#         continue\n",
    "#     params = parameter.numel()\n",
    "#     print(f\"{name}, {params}\")\n",
    "#     total_params+=params\n",
    "# print(f\"Total Trainable Params: {total_params}\")\n",
    "    \n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train, y_train = torch.tensor(trainX), torch.tensor(trainY)\n",
    "X_val, y_val = torch.tensor(valX), torch.tensor(valY)\n",
    "X_test, y_test = torch.tensor(testX), torch.tensor(testY)\n",
    "\n",
    "# Create DataLoader for training and validation data\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001, eps=1e-07)\n",
    "# optimizer = optim.Adam(model.parameters())\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 4  # Replace with your desired number of epochs\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), total= num_epochs, desc=\"epochs\", position=0, leave=True):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for inputs, targets in tqdm(train_loader, total=len(train_loader), desc=\"train batches\", position=1, leave=True):\n",
    "        inputs, targets = inputs.nan_to_num().to(device), targets.nan_to_num().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "#         print(\"targets: \", targets.shape)\n",
    "#         print(\"outputs: \", outputs.shape)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         for p in model.parameters():\n",
    "#             print(p.grad.norm())\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(val_loader, total=len(val_loader), desc=\"val batches\", position=2, leave=True):\n",
    "            inputs, targets = inputs.nan_to_num().to(device), targets.nan_to_num().to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, targets).item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Training Loss: {train_loss:.6f}, Validation Loss: {val_loss:.6f}')\n",
    "\n",
    "# Save the PyTorch model\n",
    "torch.save(model.state_dict(), 'transformer_5min.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bff4271e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 1632, 6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9835bc4d82542c88b825bf46778467f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test batch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0769\n",
      "(40, 6, 48)\n",
      "(40, 6, 1632)\n",
      "(40, 6, 1680)\n"
     ]
    }
   ],
   "source": [
    "# Load the PyTorch model\n",
    "loaded_model = SWT_Transformer(seq_len, inp_len, out_len, d_k, d_v, n_heads, ff_dim, param_dset_forecast)\n",
    "loaded_model.load_state_dict(torch.load('transformer_5min.pth'))\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "# Use the whole signal (both train and validation data)\n",
    "# The metrics are computed only using the validation part.\n",
    "# This is needed for the signal processing\n",
    "print(testX.shape)\n",
    "\n",
    "# Testing the model on the test dataset\n",
    "test_outputs = []\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in tqdm(test_loader, total=len(test_loader), desc=\"test batch\"):\n",
    "        inputs, targets = inputs.nan_to_num().to(device), targets.nan_to_num().to(device)\n",
    "        outputs = loaded_model(inputs)\n",
    "        test_outputs.append(outputs.cpu().numpy())  # Collect the outputs\n",
    "        test_loss += criterion(outputs, targets).item()\n",
    "\n",
    "testPredict_a = np.concatenate(test_outputs, axis=0)  # Concatenate outputs into a single numpy array\n",
    "test_loss /= len(test_loader)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "\n",
    "# Result from test\n",
    "print(testPredict_a.shape)\n",
    "\n",
    "testX_original = np.transpose(testX, (0, 2, 1))\n",
    "print(testX_original.shape)\n",
    "\n",
    "test_cat = np.concatenate((testX_original, testPredict_a), axis=2) \n",
    "print(test_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "602a4a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 10080)\n",
      "(40, 3, 2, 1680)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ee2101fe474d739215c3243248750a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iswt:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 1680)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "D = test_cat.reshape(test_cat.shape[0],test_cat.shape[1]*test_cat.shape[2])\n",
    "print(D.shape)\n",
    "\n",
    "R = D.reshape(test_cat.shape[0],lev,2,test_cat.shape[2])\n",
    "print(R.shape)\n",
    "\n",
    "R = data_organization(R)\n",
    "\n",
    "# print(R)\n",
    "\n",
    "re=data_reconstruction(R)\n",
    "Re = np.array(re)\n",
    "print(Re.shape)\n",
    "\n",
    "\n",
    "Re = np.nan_to_num(Re)\n",
    "\n",
    "Re = torch.from_numpy(Re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "134a66ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy shape:  (97143, 1680)\n",
      "Real test shape:  torch.Size([40, 1680])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"numpy shape: \", self_series_numpy.shape)\n",
    "# test_compare = self_series_numpy[160:200, :]\n",
    "test_compare = self_series[1160:1200, :].nan_to_num()\n",
    "print(\"Real test shape: \", test_compare.shape)\n",
    "\n",
    "test_rmse = math.sqrt( mean_squared_error(test_compare[:,param_dset_lookback:], Re[:,param_dset_lookback:]))\n",
    "# test_rmse = math.sqrt( mean_squared_error(test_compare, Re))\n",
    "\n",
    "test_mae=mean_absolute_error(test_compare[:,param_dset_lookback:], Re[:,param_dset_lookback:])\n",
    "# test_mae=mean_absolute_error(test_compare, Re)\n",
    "\n",
    "test_smape = (2*(test_compare[:,param_dset_lookback:]-Re[:,param_dset_lookback:]).abs_() / (test_compare[:,param_dset_lookback:].abs() + Re[:,param_dset_lookback:].abs())).nanmean()\n",
    "\n",
    "# mape=100*np.mean(np.divide(abs(test_compare[:,1632:]- Re[:,1632:]),test_compare[:,1632:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed6df351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.171455\n",
      "MAE:  0.106719\n",
      "MAPE:  0.765961\n"
     ]
    }
   ],
   "source": [
    "print('RMSE:  %.6f' % test_rmse)\n",
    "print('MAE:  %.6f' % test_mae)\n",
    "print('sMAPE:  %.6f' % test_smape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca1d17c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swt_env",
   "language": "python",
   "name": "swt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
