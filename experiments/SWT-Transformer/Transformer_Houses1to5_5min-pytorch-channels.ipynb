{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b339f2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16694361915207433747\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4268752896\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9320447973995574158\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "import tensorflow as tf\n",
    "print(device_lib.list_local_devices())\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f86f97af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests require pytest, pytest not installed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "h5py.run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecda64f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lyes @2022\n",
    "# The data could be found in http://keddiyan.com/files/PowerForecast.html\n",
    "# and T.-Y. Kim and S.-B. Cho, ‘‘Predicting residential energy consumption using CNN–LSTM neural networks,’’ Energy, vol. 182, pp. 72–81, Sep. 2019.\n",
    "# https://towardsdatascience.com/the-time-series-transformer-2a521a0efad3\n",
    "\n",
    "#https://github.com/LyesSaadSaoud/House_transformer/blob/main/Transformers_Houses1to5_5min.py\n",
    "import sys\n",
    "sys.path.append(\"mypath\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os, datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import pywt\n",
    "import tensorflow\n",
    "from numpy.random import seed\n",
    "# plt.style.use('seaborn')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b70c46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {\n",
    "    'Year': 'Int64',\n",
    "    'Month': 'Int64',\n",
    "    'Day': 'Int64',\n",
    "    'Hour': 'Int64',\n",
    "    'Minute': 'Int64',\n",
    "    'Global_active_power':'float32',\n",
    "    'Global_reactive_power':'float32',\n",
    "    'Voltage;Global_intensity':'float32',\n",
    "    'Sub_metering_1':'float32',\n",
    "    'Sub_metering_2':'float32',\n",
    "    'Sub_metering_3':'float32'\n",
    "}\n",
    "\n",
    "def save_result(y_test,predicted_values):\n",
    "    np.savetxt('./T_SWT_house4_min5_test.csv',y_test) # save path\n",
    "    np.savetxt('./T_SWT_house4_min5_predicted.csv',predicted_values) # save path\n",
    "\n",
    "df = pd.read_csv('./data ukdale/house1_5mins.csv', dtype=dtype)  # path to data\n",
    "\n",
    "def data_preparation(dataset, window, lev):\n",
    "    da = []\n",
    "    for i in range(len(dataset)-window):\n",
    "        coeffs = pywt.swt(dataset[i:window+i], wavelet='db2', level=lev)\n",
    "        da.append(coeffs);\n",
    "    return da\n",
    "\n",
    "def data_reconstruction(dataset,window):\n",
    "    da = []\n",
    "    for i in tqdm(range(len(dataset)), total= len(dataset), desc=\"iswt\"):\n",
    "#         recon = pywt.iswt(dataset[i,:,:,:].tolist(), 'db2')\n",
    "        recon = pywt.iswt(dataset[i], 'db2')\n",
    "#         print(np.array(recon).shape)\n",
    "        da.append(recon[window-1])\n",
    "#         da.append(recon[0][window-1])\n",
    "    return da\n",
    "\n",
    "\n",
    "# Called because iswt cannot accept tolist() dataset\n",
    "def data_organization(coeffs):\n",
    "    '''\n",
    "    Reshape data back to (n,3,2,window_length), where there are 3 tuples of 2 values consisting of \n",
    "    coeffs array_like Coefficients list of tuples:\n",
    "    [(cAn, cDn), ..., (cA2, cD2), (cA1, cD1)]\n",
    "    '''\n",
    "    reshape_list = []\n",
    "    for i in range(len(coeffs)):\n",
    "        reshape_list.append([])\n",
    "        for j in range(len(coeffs[0])):\n",
    "            reshape_list[i].append(tuple(coeffs[i][j]))\n",
    "            \n",
    "    return reshape_list\n",
    "\n",
    "def create_dataset(dataset, look_back):\n",
    "    dataX,dataY=[],[]\n",
    "\n",
    "    for i in range(len(dataset)-look_back):\n",
    "        a=dataset[i:(i+look_back),0:4]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i+look_back,0:4])\n",
    "    return np.array(dataX),np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40e46b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# class Time2Vector(Layer):\n",
    "#     ''' https://arxiv.org/abs/1907.05321'''\n",
    "#     def __init__(self, seq_len, **kwargs):\n",
    "#         super(Time2Vector, self).__init__()\n",
    "#         self.seq_len = seq_len\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         self.weights_linear = self.add_weight(name='weight_linear',\n",
    "#                                               shape=(int(self.seq_len),),\n",
    "#                                               initializer='uniform',\n",
    "#                                               trainable=True)\n",
    "\n",
    "#         self.bias_linear = self.add_weight(name='bias_linear',\n",
    "#                                            shape=(int(self.seq_len),),\n",
    "#                                            initializer='uniform',\n",
    "#                                            trainable=True)\n",
    "\n",
    "#         self.weights_periodic = self.add_weight(name='weight_periodic',\n",
    "#                                                 shape=(int(self.seq_len),),\n",
    "#                                                 initializer='uniform',\n",
    "#                                                 trainable=True)\n",
    "\n",
    "#         self.bias_periodic = self.add_weight(name='bias_periodic',\n",
    "#                                              shape=(int(self.seq_len),),\n",
    "#                                              initializer='uniform',\n",
    "#                                              trainable=True)\n",
    "\n",
    "#     def call(self, x):\n",
    "\n",
    "#         x = tf.math.reduce_mean(x[:, :, :4], axis=-1)\n",
    "#         time_linear = self.weights_linear * x + self.bias_linear\n",
    "#         time_linear = tf.expand_dims(time_linear, axis=-1)\n",
    "\n",
    "#         time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n",
    "#         time_periodic = tf.expand_dims(time_periodic, axis=-1)\n",
    "#         return tf.concat([time_linear, time_periodic], axis=-1)\n",
    "\n",
    "#     def get_config(self):\n",
    "#         config = super().get_config().copy()\n",
    "#         config.update({'seq_len': self.seq_len})\n",
    "#         return config\n",
    "    \n",
    "class Time2Vector(nn.Module):\n",
    "    def __init__(self, seq_len):\n",
    "        super(Time2Vector, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        self.weights_linear = nn.Parameter(torch.rand(seq_len, requires_grad=True))\n",
    "        self.bias_linear = nn.Parameter(torch.rand(seq_len), requires_grad=True)\n",
    "        self.weights_periodic = nn.Parameter(torch.rand(seq_len), requires_grad=True)\n",
    "        self.bias_periodic = nn.Parameter(torch.rand(seq_len), requires_grad=True)\n",
    "        \n",
    "        # Initialize parameters with uniform distribution\n",
    "        nn.init.uniform_(self.weights_linear, a=0.0, b=1.0)\n",
    "        nn.init.uniform_(self.bias_linear, a=0.0, b=1.0)\n",
    "        nn.init.uniform_(self.weights_periodic, a=0.0, b=1.0)\n",
    "        nn.init.uniform_(self.bias_periodic, a=0.0, b=1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.mean(x[:, :, :], dim=-2)\n",
    "        time_linear = self.weights_linear * x + self.bias_linear\n",
    "        time_linear = time_linear.unsqueeze(-2)\n",
    "\n",
    "        time_periodic = torch.sin(x * self.weights_periodic + self.bias_periodic)\n",
    "        time_periodic = time_periodic.unsqueeze(-2)\n",
    "\n",
    "        return torch.cat([time_linear, time_periodic], dim=-2)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f'seq_len={self.seq_len}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1519e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SingleAttention(Layer):\n",
    "#     def __init__(self, d_k, d_v):\n",
    "#         super(SingleAttention, self).__init__()\n",
    "#         self.d_k = d_k\n",
    "#         self.d_v = d_v\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         self.query = Dense(self.d_k,\n",
    "#                            input_shape=input_shape,\n",
    "#                            kernel_initializer='glorot_uniform',\n",
    "#                            bias_initializer='glorot_uniform')\n",
    "\n",
    "#         self.key = Dense(self.d_k,\n",
    "#                          input_shape=input_shape,\n",
    "#                          kernel_initializer='glorot_uniform',\n",
    "#                          bias_initializer='glorot_uniform')\n",
    "\n",
    "#         self.value = Dense(self.d_v,\n",
    "#                            input_shape=input_shape,\n",
    "#                            kernel_initializer='glorot_uniform',\n",
    "#                            bias_initializer='glorot_uniform')\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         q = self.query(inputs[0])\n",
    "#         k = self.key(inputs[1])\n",
    "\n",
    "#         attn_weights = tf.matmul(q, k, transpose_b=True)\n",
    "#         attn_weights = tf.map_fn(lambda x: x / np.sqrt(self.d_k), attn_weights)\n",
    "#         attn_weights = tf.nn.softmax(attn_weights, axis=-1)\n",
    "\n",
    "#         v = self.value(inputs[2])\n",
    "#         attn_out = tf.matmul(attn_weights, v)\n",
    "#         return attn_out\n",
    "\n",
    "class SingleAttention(nn.Module):\n",
    "    def __init__(self, d_k, d_v):\n",
    "        super(SingleAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "        self.query = nn.Linear(in_features=1, out_features=d_k)\n",
    "        nn.init.xavier_uniform_(self.query.weight)\n",
    "        nn.init.zeros_(self.query.bias)\n",
    "\n",
    "        self.key = nn.Linear(in_features=1, out_features=d_k)\n",
    "        nn.init.xavier_uniform_(self.key.weight)\n",
    "        nn.init.zeros_(self.key.bias)\n",
    "\n",
    "        self.value = nn.Linear(in_features=1, out_features=d_v)\n",
    "        nn.init.xavier_uniform_(self.value.weight)\n",
    "        nn.init.zeros_(self.value.bias)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        q = self.query(inputs[0])\n",
    "        k = self.key(inputs[1])\n",
    "\n",
    "        attn_weights = torch.matmul(q, k.transpose(-2, -1))\n",
    "        attn_weights = attn_weights / torch.sqrt(torch.tensor(self.d_k, dtype=torch.float32))\n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "\n",
    "        v = self.value(inputs[2])\n",
    "        attn_out = torch.matmul(attn_weights, v)\n",
    "#         print(\"attn_out: \", attn_out.shape)\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdf84fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiAttention(Layer):\n",
    "#     def __init__(self, d_k, d_v, n_heads):\n",
    "#         super(MultiAttention, self).__init__()\n",
    "#         self.d_k = d_k\n",
    "#         self.d_v = d_v\n",
    "#         self.n_heads = n_heads\n",
    "#         self.attn_heads = list()\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         for n in range(self.n_heads):\n",
    "#             self.attn_heads.append(SingleAttention(self.d_k, self.d_v))\n",
    "#         self.linear = Dense(input_shape[0][-1],\n",
    "#                             input_shape=input_shape,\n",
    "#                             kernel_initializer='glorot_uniform',\n",
    "#                             bias_initializer='glorot_uniform')\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]\n",
    "#         concat_attn = tf.concat(attn, axis=-1)\n",
    "#         multi_linear = self.linear(concat_attn)\n",
    "#         return multi_linear\n",
    "    \n",
    "class MultiAttention(nn.Module):\n",
    "    def __init__(self, d_k, d_v, n_heads):\n",
    "        super(MultiAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        self.attn_heads = nn.ModuleList([SingleAttention(d_k, d_v) for _ in range(n_heads)])\n",
    "        \n",
    "        self.linear = nn.Linear(d_k * n_heads, 1)\n",
    "        nn.init.xavier_uniform_(self.linear.weight)\n",
    "        nn.init.zeros_(self.linear.bias)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]\n",
    "        concat_attn = torch.cat(attn, dim=-1)\n",
    "#         print(\"concat_attn: \", concat_attn.shape)\n",
    "        multi_linear = self.linear(concat_attn)\n",
    "#         print(\"multi_linear: \", multi_linear.shape)\n",
    "        return multi_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c3c255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TransformerEncoder(Layer):\n",
    "#     def __init__(self, d_k, d_v, n_heads, ff_dim, dropout=0.1, **kwargs):\n",
    "#         super(TransformerEncoder, self).__init__()\n",
    "#         self.d_k = d_k\n",
    "#         self.d_v = d_v\n",
    "#         self.n_heads = n_heads\n",
    "#         self.ff_dim = ff_dim\n",
    "#         self.attn_heads = list()\n",
    "#         self.dropout_rate = dropout\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         self.attn_multi = MultiAttention(self.d_k, self.d_v, self.n_heads)\n",
    "#         self.attn_dropout = Dropout(self.dropout_rate)\n",
    "#         self.attn_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
    "\n",
    "#         self.ff_conv1D_1 = Conv1D(filters=self.ff_dim, kernel_size=1, activation='relu')\n",
    "#         self.ff_conv1D_2 = Conv1D(filters=input_shape[0][-1], kernel_size=1)\n",
    "#         self.ff_dropout = Dropout(self.dropout_rate)\n",
    "#         self.ff_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
    "\n",
    "#     def call(self, inputs):  # inputs = (in_seq, in_seq, in_seq)\n",
    "#         attn_layer = self.attn_multi(inputs)\n",
    "#         attn_layer = self.attn_dropout(attn_layer)\n",
    "#         attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n",
    "\n",
    "#         ff_layer = self.ff_conv1D_1(attn_layer)\n",
    "#         ff_layer = self.ff_conv1D_2(ff_layer)\n",
    "#         ff_layer = self.ff_dropout(ff_layer)\n",
    "#         ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
    "#         return ff_layer\n",
    "\n",
    "#     def get_config(self):\n",
    "#         config = super().get_config().copy()\n",
    "#         config.update({'d_k': self.d_k,\n",
    "#                        'd_v': self.d_v,\n",
    "#                        'n_heads': self.n_heads,\n",
    "#                        'ff_dim': self.ff_dim,\n",
    "#                        'attn_heads': self.attn_heads,\n",
    "#                        'dropout_rate': self.dropout_rate})\n",
    "#         return config\n",
    "\n",
    "    \n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_k, d_v, n_heads, ff_dim, dropout=0.1):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.n_heads = n_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.dropout_rate = dropout\n",
    "\n",
    "        self.attn_multi = MultiAttention(d_k, d_v, n_heads)\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        self.attn_normalize = nn.LayerNorm(normalized_shape=1, eps=1e-6)\n",
    "\n",
    "        self.ff_conv1D_1 = nn.Conv1d(in_channels=8, out_channels=self.ff_dim, kernel_size=1)\n",
    "#         self.ff_conv1D_1 = nn.Conv1d(in_channels=1, out_channels=self.ff_dim, kernel_size=1)\n",
    "        self.ff_conv1D_2 = nn.Conv1d(in_channels=self.ff_dim, out_channels=8, kernel_size=1)\n",
    "#         self.ff_conv1D_2 = nn.Conv1d(in_channels=self.ff_dim, out_channels=1, kernel_size=1)\n",
    "        self.ff_dropout = nn.Dropout(dropout)\n",
    "        self.ff_normalize = nn.LayerNorm(normalized_shape=1, eps=1e-6)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "#         print(len(inputs))\n",
    "#         print(inputs[0].shape)\n",
    "        attn_layer = self.attn_multi(inputs)\n",
    "        attn_layer = self.attn_dropout(attn_layer)\n",
    "        attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n",
    "\n",
    "        # Correction for transpose\n",
    "#         ff_layer = self.ff_conv1D_1(attn_layer.transpose(1, 2))\n",
    "        ff_layer = self.ff_conv1D_1(attn_layer)\n",
    "        ff_layer = F.relu(ff_layer)\n",
    "#         ff_layer = self.ff_conv1D_2(ff_layer).transpose(1, 2)\n",
    "        ff_layer = self.ff_conv1D_2(ff_layer)\n",
    "        ff_layer = self.ff_dropout(ff_layer)\n",
    "        ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
    "        return ff_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c79145b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TransformerDecoder(Layer):\n",
    "#     def __init__(self, d_k, d_v, n_heads, ff_dim, dropout=0.1, **kwargs):\n",
    "#         super(TransformerDecoder, self).__init__()\n",
    "#         self.d_k = d_k\n",
    "#         self.d_v = d_v\n",
    "#         self.n_heads = n_heads\n",
    "#         self.ff_dim = ff_dim\n",
    "#         self.attn_heads = list()\n",
    "#         self.dropout_rate = dropout\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         self.attn_multi = MultiAttention(self.d_k, self.d_v, self.n_heads)\n",
    "#         self.attn_dropout = Dropout(self.dropout_rate)\n",
    "#         self.attn_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
    "\n",
    "#         self.ff_conv1D_1 = Conv1D(filters=input_shape[0][-1], kernel_size=1, activation='relu')\n",
    "#         self.ff_dropout = Dropout(self.dropout_rate)\n",
    "#         self.ff_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
    "\n",
    "#     def call(self, inputs):  # inputs = (in_seq, in_seq, in_seq)\n",
    "#         attn_layer = self.attn_multi(inputs)\n",
    "#         attn_layer = self.attn_dropout(attn_layer)\n",
    "#         attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n",
    "\n",
    "#         ff_layer = self.ff_conv1D_1(attn_layer)\n",
    "#         ff_layer = self.ff_dropout(ff_layer)\n",
    "#         ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
    "#         return ff_layer\n",
    "\n",
    "#     def get_config(self):  # Needed for saving and loading model with custom layer\n",
    "#         config = super().get_config().copy()\n",
    "#         config.update({'d_k': self.d_k,\n",
    "#                        'd_v': self.d_v,\n",
    "#                        'n_heads': self.n_heads,\n",
    "#                        'ff_dim': self.ff_dim,\n",
    "#                        'attn_heads': self.attn_heads,\n",
    "#                        'dropout_rate': self.dropout_rate})\n",
    "#         return config\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, d_k, d_v, n_heads, ff_dim, dropout=0.1):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.n_heads = n_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.dropout_rate = dropout\n",
    "\n",
    "        self.attn_multi = MultiAttention(d_k, d_v, n_heads)\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        self.attn_normalize = nn.LayerNorm(normalized_shape=1, eps=1e-6)\n",
    "\n",
    "        self.ff_conv1D_1 = nn.Conv1d(in_channels=8, out_channels=8, kernel_size=1)\n",
    "#         self.ff_conv1D_1 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=1)\n",
    "        self.ff_dropout = nn.Dropout(dropout)\n",
    "        self.ff_normalize = nn.LayerNorm(normalized_shape=1, eps=1e-6)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        attn_layer = self.attn_multi(inputs)\n",
    "        attn_layer = self.attn_dropout(attn_layer)\n",
    "        attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n",
    "        \n",
    "        # Transpose for pytorch implementation\n",
    "#         ff_layer = self.ff_conv1D_1(attn_layer.transpose(1, 2)).transpose(1, 2)\n",
    "        ff_layer = self.ff_conv1D_1(attn_layer)\n",
    "        ff_layer = F.relu(ff_layer)\n",
    "        ff_layer = self.ff_dropout(ff_layer)\n",
    "        ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
    "        return ff_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1c8c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model():\n",
    "#   time_embedding = Time2Vector(seq_len)\n",
    "#   layer1 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "#   layer2 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "#   layer3 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "#   layer4 = TransformerDecoder(d_k, d_v, n_heads, ff_dim)\n",
    "#   layer5 = TransformerDecoder(d_k, d_v, n_heads, ff_dim)\n",
    "#   in_seq = Input(shape=(seq_len, inp_len))\n",
    "\n",
    "#   x = time_embedding(in_seq)\n",
    "#   x = Concatenate(axis=-1)([in_seq, x])\n",
    "#   x = layer1((x, x, x))\n",
    "#   x = layer2((x, x, x))\n",
    "#   x = layer3((x, x, x))\n",
    "#   x = layer4((x, x, x))\n",
    "#   x = layer5((x, x, x))\n",
    "#   x = GlobalAveragePooling1D(data_format='channels_first')(x)\n",
    "#   x = Dropout(0.1)(x)\n",
    "#   x = Dense(128, activation='relu')(x)\n",
    "#   x = Dropout(0.1)(x)\n",
    "#   out = Dense(out_len, activation='linear')(x)\n",
    "\n",
    "#   model = Model(inputs=in_seq, outputs=out)\n",
    "#   model.compile(loss='mse', optimizer='RMSProp', metrics=['mae', 'mape'])\n",
    "#   return model\n",
    "\n",
    "# Put inside nn.module for model.parameters\n",
    "# def create_model(seq_len, inp_len, out_len, d_k, d_v, n_heads, ff_dim):\n",
    "#     time_embedding = Time2Vector(seq_len)\n",
    "#     layer1 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "#     layer2 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "#     layer3 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "#     layer4 = TransformerDecoder(d_k, d_v, n_heads, ff_dim)\n",
    "#     layer5 = TransformerDecoder(d_k, d_v, n_heads, ff_dim)\n",
    "\n",
    "#     # Create required shape tensor for time embedding\n",
    "#     in_seq = torch.rand(1,seq_len, inp_len)\n",
    "# #     print(in_seq.shape)\n",
    "\n",
    "#     x = time_embedding(in_seq)\n",
    "# #     print(x.shape)\n",
    "#     x = torch.cat([in_seq, x], dim=-1)\n",
    "# #     print(x.shape)\n",
    "    \n",
    "#     x = layer1((x, x, x))\n",
    "#     x = layer2((x, x, x))\n",
    "#     x = layer3((x, x, x))\n",
    "#     x = layer4((x, x, x))\n",
    "#     x = layer5((x, x, x))\n",
    "\n",
    "#     # Global Average Pooling along the sequence dimension\n",
    "#     x = F.adaptive_avg_pool1d(x, 1).squeeze(2)\n",
    "    \n",
    "#     x = F.dropout(x, p=0.1)\n",
    "#     x = F.relu(nn.Linear(x.size(1), 128)(x))\n",
    "#     x = F.dropout(x, p=0.1)\n",
    "#     out = nn.Linear(128, out_len)(x)\n",
    "\n",
    "#     return out\n",
    "\n",
    "class SWT_Transformer(nn.Module):\n",
    "    def __init__(self, seq_len, inp_len, out_len, d_k, d_v, n_heads, ff_dim):\n",
    "        super(SWT_Transformer, self).__init__()\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.time_embedding = Time2Vector(seq_len)\n",
    "        \n",
    "        self.layer1 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "        self.layer2 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "        self.layer3 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "        self.layer4 = TransformerDecoder(d_k, d_v, n_heads, ff_dim)\n",
    "        self.layer5 = TransformerDecoder(d_k, d_v, n_heads, ff_dim)\n",
    "\n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Linear(8, 128)\n",
    "        self.fc2 = nn.Linear(128, out_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_seq = x\n",
    "        \n",
    "        time_embedding = self.time_embedding(in_seq)\n",
    "        x = torch.cat([in_seq, time_embedding], dim=-2)\n",
    "#         print(\"time embed: \", x.shape)\n",
    "        \n",
    "        x = self.layer1((x, x, x))\n",
    "#         print(\"layer 1: \", x.shape)\n",
    "        x = self.layer2((x, x, x))\n",
    "#         print(\"layer 2: \", x.shape)\n",
    "        x = self.layer3((x, x, x))\n",
    "#         print(\"layer 3: \", x.shape)\n",
    "        x = self.layer4((x, x, x))\n",
    "#         print(\"layer 4: \", x.shape)\n",
    "        x = self.layer5((x, x, x))\n",
    "#         print(\"layer 5: \", x.shape)\n",
    "\n",
    "        x = self.pooling(x).squeeze(2)\n",
    "#         print(\"pooling size:\", x.shape)\n",
    "        x = F.dropout(x, p=0.1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.1)\n",
    "        out = self.fc2(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a55a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seq_len = 1\n",
    "d_k = 256\n",
    "d_v = 256\n",
    "n_heads = 12\n",
    "ff_dim = 256\n",
    "lev=3\n",
    "inp_len=2*lev\n",
    "out_len=2*lev\n",
    "window = 200\n",
    "look_back = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2009f68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum decomposition level: 5\n",
      "(36000,)\n",
      "<class 'numpy.ndarray'>\n",
      "(35800, 3, 2, 200)\n",
      "(35800, 1200)\n",
      "(35800, 6, 200)\n"
     ]
    }
   ],
   "source": [
    "# print(df.head())\n",
    "# print(df.dtypes)\n",
    "dataset = df['Volt-Ampere'].values\n",
    "dataset=dataset.astype('float32')\n",
    "\n",
    "# print(\"Dataset Shape:\", dataset.shape)\n",
    "# print(\"Dataset Length:\", len(dataset))\n",
    "\n",
    "s = dataset[:12000*3]\n",
    "# s = np.squeeze(dataset[:12000*3], axis=1)  #\n",
    "\n",
    "# Get the maximum decomposition level\n",
    "max_level = pywt.swt_max_level(len(s))\n",
    "print(\"Maximum decomposition level:\", max_level)\n",
    "\n",
    "print(s.shape)\n",
    "\n",
    "scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "print(type(s))\n",
    "da=data_preparation(s, window, lev)\n",
    "# print(da[0][0])\n",
    "\n",
    "Vv = np.array(da)\n",
    "print(Vv.shape)\n",
    "# print(Vv[0][0])\n",
    "\n",
    "vv = Vv.reshape(Vv.shape[0],2*lev*Vv.shape[3])\n",
    "print(vv.shape)\n",
    "\n",
    "\n",
    "dataset = scaler.fit_transform(vv)\n",
    "\n",
    "dat = dataset.reshape(Vv.shape[0],2*lev,Vv.shape[3])\n",
    "print(dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e906be69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35800, 6, 200)\n",
      "(23867, 6, 1)\n",
      "(11933, 6, 1)\n",
      "(35800, 6, 1)\n",
      "[[ 1.6389904  -0.29261875  1.3235514   0.21018282  1.178216   -0.3873372 ]\n",
      " [ 1.5000339  -0.36482608  1.1832415  -0.11434288  0.81986505  0.32522598]\n",
      " [ 1.3207982  -0.44874418  0.9657924  -0.38923976  0.7385761  -0.05836863]\n",
      " ...\n",
      " [ 1.3501009  -0.73547333  0.9662913  -0.5818287   0.82688606 -0.64926857]\n",
      " [ 1.2425035  -0.74713445  0.8286655  -0.49832514  0.65947026 -0.5523617 ]\n",
      " [ 1.0460081  -0.70966685  0.65473795 -0.5167357   0.50219625 -0.39625642]]\n"
     ]
    }
   ],
   "source": [
    "print(dat.shape)\n",
    "alpha=0.6667\n",
    "\n",
    "# alpha = 0.6\n",
    "# beta = 0.8\n",
    "\n",
    "trainX,trainY=dat[:int(dat.shape[0]*alpha),:,window-seq_len-1:window-1],dat[:int(dat.shape[0]*alpha),:,window-1]\n",
    "testX,testY=dat[int(dat.shape[0]*alpha):,:,window-seq_len-1:window-1],dat[int(dat.shape[0]*alpha):,:,window-1]\n",
    "testX_a, testY_a = dat[:,:,window-seq_len-1:window-1],dat[:,:,window-1]\n",
    "\n",
    "print(trainX.shape)\n",
    "print(testX.shape)\n",
    "print(testX_a.shape)\n",
    "print(trainY)\n",
    "\n",
    "# testX_a=np.transpose(testX_a, (0, 2, 1))\n",
    "# trainX=np.transpose(trainX, (0, 2, 1))\n",
    "# testX =np.transpose(testX, (0, 2, 1))\n",
    "\n",
    "# print(testX_a.shape)\n",
    "# print(trainX.shape)\n",
    "# print(testX.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c29e1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual number of model parameters: 122699\n",
      "Trainable model parameters: 122699\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920de606620a484f900e6744d11d9504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd65916ff21548369fb71e0e97014dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train batches:   0%|          | 0/746 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9c60a8e638472aaca3c48a660ccc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val batches:   0%|          | 0/373 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Training Loss: 1.018834, Validation Loss: 0.963277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61461bd2487e4542ad3e0a573d992f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train batches:   0%|          | 0/746 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model = create_model()\n",
    "# model.summary()\n",
    "\n",
    "# # Training data\n",
    "# X_train, y_train = trainX,trainY\n",
    "# ###############################################################################\n",
    "# # Validation data\n",
    "# X_val, y_val = testX,testY\n",
    "# ###############################################################################\n",
    "# # Test data\n",
    "# X_test, y_test = testX_a,testY_a\n",
    "# callback = tf.keras.callbacks.ModelCheckpoint('Transformer_5min.hdf5',\n",
    "#                                                       monitor='val_loss',\n",
    "#                                                       save_best_only=True,\n",
    "#                                                       verbose=1)\n",
    "# with tf.device(\"/gpu:0\"):\n",
    "#     history = model.fit(X_train, y_train,\n",
    "#                             batch_size=batch_size,\n",
    "# #                             epochs=50,\n",
    "#                             epochs=1,\n",
    "#                             validation_data=(X_val, y_val),\n",
    "#                             callbacks=[callback])\n",
    "\n",
    "# model = tf.keras.models.load_model('Transformer_5min.hdf5',\n",
    "#                                            custom_objects={'Time2Vector': Time2Vector,\n",
    "#                                                            'SingleAttention': SingleAttention,\n",
    "#                                                            'MultiAttention': MultiAttention,\n",
    "#                                                            'TransformerEncoder': TransformerEncoder,\n",
    "#                                                            'TransformerDecoder': TransformerDecoder}\n",
    "#                                            )\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Create PyTorch model\n",
    "model = SWT_Transformer(seq_len, inp_len, out_len, d_k, d_v, n_heads, ff_dim)\n",
    "\n",
    "# Print model summary\n",
    "# print(model)\n",
    "def num_parameters(m):\n",
    "  return sum([p.numel() for p in m.parameters()])\n",
    "\n",
    "parameters = num_parameters(model)\n",
    "\n",
    "# print(f\"Expected number of parameters: {m * dk * dk + m * 1 * 1 * n}\")\n",
    "print(f\"Actual number of model parameters: {parameters}\")\n",
    "\n",
    "trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad\n",
    ")\n",
    "print(f\"Trainable model parameters: {trainable_params}\" )\n",
    "\n",
    "# total_params = 0\n",
    "# for name, parameter in model.named_parameters():\n",
    "#     if not parameter.requires_grad:\n",
    "#         continue\n",
    "#     params = parameter.numel()\n",
    "#     print(f\"{name}, {params}\")\n",
    "#     total_params+=params\n",
    "# print(f\"Total Trainable Params: {total_params}\")\n",
    "    \n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train, y_train = torch.tensor(trainX), torch.tensor(trainY)\n",
    "X_val, y_val = torch.tensor(testX), torch.tensor(testY)\n",
    "X_test, y_test = torch.tensor(testX_a), torch.tensor(testY_a)\n",
    "\n",
    "# Create DataLoader for training and validation data\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001, eps=1e-07,)\n",
    "# optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5  # Replace with your desired number of epochs\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), total= num_epochs, desc=\"epochs\", position=0, leave=True):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for inputs, targets in tqdm(train_loader, total=len(train_loader), desc=\"train batches\", position=1, leave=True):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "#         print(\"targets: \", targets)\n",
    "#         print(\"outputs: \", outputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         for p in model.parameters():\n",
    "#             print(p.grad.norm())\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(val_loader, total=len(val_loader), desc=\"val batches\", position=2, leave=True):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, targets).item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Training Loss: {train_loss:.6f}, Validation Loss: {val_loss:.6f}')\n",
    "\n",
    "# Save the PyTorch model\n",
    "torch.save(model.state_dict(), 'transformer_5min.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118d5031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PyTorch model\n",
    "loaded_model = SWT_Transformer(seq_len, inp_len, out_len, d_k, d_v, n_heads, ff_dim)\n",
    "loaded_model.load_state_dict(torch.load('transformer_5min.pth'))\n",
    "loaded_model.eval()\n",
    "\n",
    "# Use the whole signal (both train and validation data)\n",
    "# The metrics are computed only using the validation part.\n",
    "# This is needed for the signal processing\n",
    "print(testX.shape)\n",
    "\n",
    "# Testing the model on the test dataset\n",
    "model.eval()\n",
    "test_outputs = []\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in tqdm(test_loader, total=len(test_loader), desc=\"test batch\"):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        test_outputs.append(outputs.cpu().numpy())  # Collect the outputs\n",
    "        test_loss += criterion(outputs, targets).item()\n",
    "\n",
    "testPredict_a = np.concatenate(test_outputs, axis=0)  # Concatenate outputs into a single numpy array\n",
    "test_loss /= len(test_loader)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "\n",
    "print(testPredict_a.shape)\n",
    "d=dat\n",
    "d[:,:,window-1]=testPredict_a\n",
    "print(d.shape)\n",
    "D = d.reshape(d.shape[0],d.shape[1]*d.shape[2])\n",
    "print(D.shape)\n",
    "\n",
    "R = scaler.inverse_transform(D)\n",
    "R = R.reshape(d.shape[0],lev,2,d.shape[2])\n",
    "print(R.shape)\n",
    "\n",
    "R = data_organization(R)\n",
    "\n",
    "re=data_reconstruction(R, window)\n",
    "Re = np.array(re)\n",
    "print(Re.shape)\n",
    "\n",
    "tY = s[window:].reshape(s[window:].shape[0],1)\n",
    "print(tY.shape)\n",
    "P1 = Re.reshape(Re.shape[0],1)\n",
    "\n",
    "testYa=tY[int(tY.shape[0]*alpha):,:] # take only the validation part\n",
    "testPredicta = P1[int(tY.shape[0]*alpha):, :] # take only the validation part\n",
    "\n",
    "# Calculate validation loss\n",
    "predicted_values, y_test=testPredicta[1:], testYa[:-1]\n",
    "test_rmse = math.sqrt( mean_squared_error(y_test, predicted_values))\n",
    "\n",
    "test_mae=mean_absolute_error(y_test, predicted_values)\n",
    "mape=100*np.mean(np.divide(abs(y_test- predicted_values),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e44900",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(y_test)\n",
    "plt.plot(predicted_values)\n",
    "plt.xlabel('Time/min')\n",
    "plt.ylabel('Electricity load (kWh)')\n",
    "plt.legend(['True', 'Predict'], loc='upper left')\n",
    "plt.show()\n",
    "print('RMSE:  %.4f' % test_rmse)\n",
    "print('MAE:  %.4f' % test_mae)\n",
    "print('MAPE:  %.4f' % mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff955bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array([i for i in range(1000)])\n",
    "window = 200\n",
    "lev = 3\n",
    "\n",
    "# Get the maximum decomposition level\n",
    "max_level = pywt.swt_max_level(len(dataset))\n",
    "print(\"Maximum decomposition level:\", max_level)\n",
    "\n",
    "coeffs = data_preparation(dataset, window, lev)\n",
    "# print(np.array(coeffs).shape)\n",
    "# print(coeffs[0][0])\n",
    "coeffs = np.array(coeffs)\n",
    "# print(coeffs.shape)\n",
    "# print(coeffs[0][0])\n",
    "\n",
    "coeffs = data_organization(coeffs)\n",
    "\n",
    "print(np.array(coeffs).shape)\n",
    "res = data_reconstruction(coeffs,window)\n",
    "print(res)\n",
    "np.array(res).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce4d43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved for full reconstruction\n",
    "def data_reconstruction(dataset,window):\n",
    "    da = []\n",
    "    for i in tqdm(range(len(dataset)), total= len(dataset), desc=\"iswt\"):\n",
    "#         recon = pywt.iswt(dataset[i,:,:,:].tolist(), 'db2')\n",
    "        recon = pywt.iswt(dataset[i], 'db2')\n",
    "#         da.append(recon[window-1])\n",
    "        da.append(recon)\n",
    "    return da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dd21ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swt_env",
   "language": "python",
   "name": "swt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
