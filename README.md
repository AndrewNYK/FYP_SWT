# Wavelet Transformation and Transformers for Time Series Prediction
This repository is part of a Final Year Project (FYP) that explores the integration of wavelet transformation with transformer models to enhance time series prediction. By leveraging the strengths of both techniques, we aim to improve the accuracy and efficiency of time series forecasting.

# Overview
Wavelet Transformation: A powerful tool for signal processing, wavelet transformation decomposes time series data into different frequency components, making it easier to analyze non-stationary signals and capture both local and global patterns.

Transformer Models: Originally designed for natural language processing, transformers excel in handling sequential data by using self-attention mechanisms. This allows the model to weigh the importance of different parts of the input sequence, capturing long-range dependencies effectively.

# Key Features
- Data Preprocessing: Utilizes wavelet transformation to decompose the time series data into multiple scales.
- Model Architecture: Implements a transformer model tailored for time series prediction, incorporating decomposed wavelet coefficients as inputs.
- Training and Evaluation: Provides scripts for training the transformer model on various datasets, along with evaluation metrics to assess performance.
- Visualization Tools: Includes tools for visualizing the wavelet decompositions, model predictions, and performance metrics.

# Results
Our experiments demonstrate that combining wavelet transformation with transformer models significantly improves prediction accuracy for various types of time series data, outperforming traditional methods.
